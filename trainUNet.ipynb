{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from unet.evaluate import evaluate\n",
    "from segmentation_experiments.data_loading import SegmentationDataSet\n",
    "from segmentation_experiments import data_loading\n",
    "from utils.dice_score import dice_loss\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'segmentation_experiments.data_loading' from '/home/rahulv/codes/robustdg/segmentation_experiments/data_loading.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Segmentation Train\n",
    "\n",
    "def train_net(net,\n",
    "              device,\n",
    "              train_path,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              val_percent: float = 0.1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              amp: bool = False,\n",
    "             dir_checkpoint='checkpoints/'):\n",
    "    # 1. Create dataset\n",
    "    dataset = data_loading.SegmentationDataSet(train_path)\n",
    "    \n",
    "\n",
    "    # 2. Split into train / validation partitions\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # (Initialize logging)\n",
    "#     experiment = wandb.init(project='Synth-Seg', resume='allow', anonymous='must')\n",
    "#     experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "#                                   val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale,\n",
    "#                                   amp=amp))\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "    ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(1, epochs+1):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "\n",
    "                assert images.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp):\n",
    "                    masks_pred = net(images)\n",
    "                    loss = criterion(masks_pred, true_masks) \\\n",
    "                           + dice_loss(F.softmax(masks_pred, dim=1).float(),\n",
    "                                       F.one_hot(true_masks, net.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                                       multiclass=True)\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "#                 experiment.log({\n",
    "#                     'train loss': loss.item(),\n",
    "#                     'step': global_step,\n",
    "#                     'epoch': epoch\n",
    "#                 })\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (10 * batch_size))\n",
    "                if division_step > 0:\n",
    "\n",
    "\n",
    "                        val_score = evaluate(net, val_loader, device)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "#                         experiment.log({\n",
    "#                             'learning rate': optimizer.param_groups[0]['lr'],\n",
    "#                             'validation Dice': val_score,\n",
    "#                             'images': wandb.Image(images[0].cpu()),\n",
    "#                             'masks': {\n",
    "#                                 'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "#                                 'pred': wandb.Image(torch.softmax(masks_pred, dim=1).argmax(dim=1)[0].float().cpu()),\n",
    "#                             },\n",
    "#                             'step': global_step,\n",
    "#                             'epoch': epoch,\n",
    "#                             **histograms\n",
    "#                         })\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint) + 'checkpoint_epoch{}.pth'.format(epoch))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')\n",
    "    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=5, help='Number of epochs')\n",
    "    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=1, help='Batch size')\n",
    "    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('--load', '-f', type=str, default=False, help='Load model from a .pth file')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=0.5, help='Downscaling factor of the images')\n",
    "    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0,\n",
    "                        help='Percent of the data that is used as validation (0-100)')\n",
    "    parser.add_argument('--amp', action='store_true', default=False, help='Use mixed precision')\n",
    "    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')\n",
    "    parser.add_argument('--classes', '-c', type=int, default=2, help='Number of classes')\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(amp=False, batch_size=1, bilinear=False, classes=2, epochs=5, load='/run/user/1024/jupyter/kernel-90af77f4-89cd-463e-b58b-1b467fdf9251.json', lr=1e-05, scale=0.5, val=10.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = get_args()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cuda\n",
      "INFO: Network:\n",
      "\t1 input channels\n",
      "\t1 output channels (classes)\n",
      "\tTransposed conv upscaling\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images\n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "net = UNet(n_channels=1, n_classes=1, bilinear=args.bilinear)\n",
    "\n",
    "logging.info(f'Network:\\n'\n",
    "             f'\\t{net.n_channels} input channels\\n'\n",
    "             f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "             f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting training:\n",
      "        Epochs:          5\n",
      "        Batch size:      8\n",
      "        Learning rate:   1e-05\n",
      "        Training size:   922\n",
      "        Validation size: 102\n",
      "        Checkpoints:     True\n",
      "        Device:          cuda\n",
      "        Images scaling:  0.5\n",
      "        Mixed Precision: False\n",
      "    \n",
      "Epoch 1/5:   1%|          | 8/922 [00:00<00:35, 26.06img/s, loss (batch)=0]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a537129da0584edb88b9f6809bdcbc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation round:   0%|          | 0/12 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahulv/codes/robustdg/robustdg/lib/python3.7/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "INFO: Validation Dice score: 1.5258790758698737e-11\n",
      "Epoch 1/5:   1%|          | 8/922 [00:02<04:35,  3.31img/s, loss (batch)=0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b3c2b4a28b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mimg_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mval_percent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           amp=args.amp)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0009da71908f>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, device, train_path, epochs, batch_size, learning_rate, val_percent, save_checkpoint, img_scale, amp, dir_checkpoint)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                            + dice_loss(F.softmax(masks_pred, dim=1).float(),\n\u001b[0;32m---> 74\u001b[0;31m                                        \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                                        multiclass=True)\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# if args.load:\n",
    "#     net.load_state_dict(torch.load(args.load, map_location=device))\n",
    "#     logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "net.to(device=device)\n",
    "train_net(net=net,\n",
    "          train_path='data/syntheticSegmentation/circle_dom1.npz',\n",
    "          epochs=args.epochs,\n",
    "          batch_size=8,\n",
    "          learning_rate=args.lr,\n",
    "          device=device,\n",
    "          img_scale=args.scale,\n",
    "          val_percent=args.val / 100,\n",
    "          amp=args.amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustdg",
   "language": "python",
   "name": "robustdg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
