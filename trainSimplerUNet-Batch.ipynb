{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from unet.evaluate import evaluate\n",
    "from segmentation_experiments.data_loading import SegmentationDataSet\n",
    "from segmentation_experiments import data_loading\n",
    "from utils.dice_score import dice_loss\n",
    "from unet import UNet\n",
    "from unet import simpleUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'unet.simpleUNet' from '/home/rahulv/codes/robustdg/unet/simpleUNet.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(data_loading)\n",
    "reload(simpleUNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = glob.glob('data/syntheticSegmentation/simple_train_dom1_*')\n",
    "val_sets = glob.glob('data/syntheticSegmentation/simple_test_dom1_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256]) torch.Size([32, 2, 256, 256])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "              ReLU-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-5         [-1, 64, 128, 128]               0\n",
      "            Conv2d-6        [-1, 128, 128, 128]          73,856\n",
      "              ReLU-7        [-1, 128, 128, 128]               0\n",
      "            Conv2d-8        [-1, 128, 128, 128]         147,584\n",
      "              ReLU-9        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-10          [-1, 128, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]         295,168\n",
      "             ReLU-12          [-1, 256, 64, 64]               0\n",
      "           Conv2d-13          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-14          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-15          [-1, 256, 32, 32]               0\n",
      "           Conv2d-16          [-1, 512, 32, 32]       1,180,160\n",
      "             ReLU-17          [-1, 512, 32, 32]               0\n",
      "           Conv2d-18          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-19          [-1, 512, 32, 32]               0\n",
      "         Upsample-20          [-1, 512, 64, 64]               0\n",
      "           Conv2d-21          [-1, 256, 64, 64]       1,769,728\n",
      "             ReLU-22          [-1, 256, 64, 64]               0\n",
      "           Conv2d-23          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-24          [-1, 256, 64, 64]               0\n",
      "         Upsample-25        [-1, 256, 128, 128]               0\n",
      "           Conv2d-26        [-1, 128, 128, 128]         442,496\n",
      "             ReLU-27        [-1, 128, 128, 128]               0\n",
      "           Conv2d-28        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-29        [-1, 128, 128, 128]               0\n",
      "         Upsample-30        [-1, 128, 256, 256]               0\n",
      "           Conv2d-31         [-1, 64, 256, 256]         110,656\n",
      "             ReLU-32         [-1, 64, 256, 256]               0\n",
      "           Conv2d-33         [-1, 64, 256, 256]          36,928\n",
      "             ReLU-34         [-1, 64, 256, 256]               0\n",
      "           Conv2d-35          [-1, 2, 256, 256]             130\n",
      "================================================================\n",
      "Total params: 7,781,826\n",
      "Trainable params: 7,781,826\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 591.00\n",
      "Params size (MB): 29.69\n",
      "Estimated Total Size (MB): 620.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for train_set_name in train_sets:\n",
    "\n",
    "    train_set = data_loading.SegmentationDataSet(train_set_name)\n",
    "    val_set = data_loading.SegmentationDataSet(val_sets[0])\n",
    "    batch_size = 32\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "        'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    }\n",
    "\n",
    "\n",
    "    # In[5]:\n",
    "\n",
    "\n",
    "    #check outputs from dataloader\n",
    "\n",
    "    inputs, masks = next(iter(dataloaders['train']))\n",
    "    print(inputs.shape, masks.shape)\n",
    "\n",
    "\n",
    "    # In[6]:\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = simpleUNet.UNet(n_class=2)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # check keras-like model summary using torchsummary\n",
    "    from torchsummary import summary\n",
    "    summary(model, input_size=(1, 256, 256))\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "    import torch\n",
    "    import torch.optim as optim\n",
    "    from torch.optim import lr_scheduler\n",
    "    from unet import training_loop\n",
    "    reload(training_loop)\n",
    "\n",
    "    optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "     \n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
    "\n",
    "    model_name = os.path.basename(train_set_name)[:-len('.npz')]\n",
    "    model, loss_values = training_loop.train_model(model, optimizer_ft, exp_lr_scheduler, dataloaders, model_name, num_epochs=45)\n",
    "\n",
    "    np.save('checkpoints/' + model_name + '_Metrics.npz', loss_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustdg",
   "language": "python",
   "name": "robustdg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
