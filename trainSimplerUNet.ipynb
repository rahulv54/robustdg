{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from unet.evaluate import evaluate\n",
    "from segmentation_experiments.data_loading import SegmentationDataSet\n",
    "from segmentation_experiments import data_loading\n",
    "from utils.dice_score import dice_loss\n",
    "from unet import UNet\n",
    "from unet import simpleUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'unet.simpleUNet' from '/home/rahulv/codes/robustdg/unet/simpleUNet.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(data_loading)\n",
    "reload(simpleUNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data_loading.SegmentationDataSet('data/syntheticSegmentation/small_train_dom2.npz')\n",
    "val_set = data_loading.SegmentationDataSet('data/syntheticSegmentation/test_dom1.npz')\n",
    "batch_size = 32\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256]) torch.Size([32, 2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "#check outputs from dataloader\n",
    "\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "print(inputs.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "              ReLU-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-5         [-1, 64, 128, 128]               0\n",
      "            Conv2d-6        [-1, 128, 128, 128]          73,856\n",
      "              ReLU-7        [-1, 128, 128, 128]               0\n",
      "            Conv2d-8        [-1, 128, 128, 128]         147,584\n",
      "              ReLU-9        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-10          [-1, 128, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]         295,168\n",
      "             ReLU-12          [-1, 256, 64, 64]               0\n",
      "           Conv2d-13          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-14          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-15          [-1, 256, 32, 32]               0\n",
      "           Conv2d-16          [-1, 512, 32, 32]       1,180,160\n",
      "             ReLU-17          [-1, 512, 32, 32]               0\n",
      "           Conv2d-18          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-19          [-1, 512, 32, 32]               0\n",
      "         Upsample-20          [-1, 512, 64, 64]               0\n",
      "           Conv2d-21          [-1, 256, 64, 64]       1,769,728\n",
      "             ReLU-22          [-1, 256, 64, 64]               0\n",
      "           Conv2d-23          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-24          [-1, 256, 64, 64]               0\n",
      "         Upsample-25        [-1, 256, 128, 128]               0\n",
      "           Conv2d-26        [-1, 128, 128, 128]         442,496\n",
      "             ReLU-27        [-1, 128, 128, 128]               0\n",
      "           Conv2d-28        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-29        [-1, 128, 128, 128]               0\n",
      "         Upsample-30        [-1, 128, 256, 256]               0\n",
      "           Conv2d-31         [-1, 64, 256, 256]         110,656\n",
      "             ReLU-32         [-1, 64, 256, 256]               0\n",
      "           Conv2d-33         [-1, 64, 256, 256]          36,928\n",
      "             ReLU-34         [-1, 64, 256, 256]               0\n",
      "           Conv2d-35          [-1, 2, 256, 256]             130\n",
      "================================================================\n",
      "Total params: 7,781,826\n",
      "Trainable params: 7,781,826\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 591.00\n",
      "Params size (MB): 29.69\n",
      "Estimated Total Size (MB): 620.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = simpleUNet.UNet(n_class=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# check keras-like model summary using torchsummary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/59\n",
      "----------\n",
      "LR 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahulv/codes/robustdg/robustdg/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/rahulv/codes/robustdg/robustdg/lib/python3.7/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: bce: 0.559628, dice: 0.562207, loss: 0.560918\n",
      "val: bce: 0.288309, dice: 0.500054, loss: 0.394181\n",
      "saving best model\n",
      "0m 44s\n",
      "Epoch 1/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.172381, dice: 0.445269, loss: 0.308825\n",
      "val: bce: 0.074010, dice: 0.329069, loss: 0.201540\n",
      "saving best model\n",
      "0m 49s\n",
      "Epoch 2/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.052607, dice: 0.232489, loss: 0.142548\n",
      "val: bce: 0.046320, dice: 0.095507, loss: 0.070914\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 3/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.019582, dice: 0.063545, loss: 0.041564\n",
      "val: bce: 0.004885, dice: 0.043716, loss: 0.024301\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 4/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.008976, dice: 0.050182, loss: 0.029579\n",
      "val: bce: 0.006121, dice: 0.044114, loss: 0.025118\n",
      "0m 50s\n",
      "Epoch 5/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.004683, dice: 0.036537, loss: 0.020610\n",
      "val: bce: 0.006377, dice: 0.037233, loss: 0.021805\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 6/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.006636, dice: 0.037414, loss: 0.022025\n",
      "val: bce: 0.003999, dice: 0.036335, loss: 0.020167\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 7/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.004159, dice: 0.030724, loss: 0.017441\n",
      "val: bce: 0.003762, dice: 0.034513, loss: 0.019137\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 8/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003633, dice: 0.028558, loss: 0.016095\n",
      "val: bce: 0.003875, dice: 0.028735, loss: 0.016305\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 9/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.008645, dice: 0.040119, loss: 0.024382\n",
      "val: bce: 0.004561, dice: 0.041526, loss: 0.023044\n",
      "0m 50s\n",
      "Epoch 10/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.004203, dice: 0.031837, loss: 0.018020\n",
      "val: bce: 0.003477, dice: 0.030630, loss: 0.017053\n",
      "0m 50s\n",
      "Epoch 11/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003498, dice: 0.028262, loss: 0.015880\n",
      "val: bce: 0.003255, dice: 0.028811, loss: 0.016033\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 12/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.004775, dice: 0.030030, loss: 0.017403\n",
      "val: bce: 0.009748, dice: 0.058443, loss: 0.034096\n",
      "0m 50s\n",
      "Epoch 13/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.006444, dice: 0.036584, loss: 0.021514\n",
      "val: bce: 0.005403, dice: 0.033723, loss: 0.019563\n",
      "0m 50s\n",
      "Epoch 14/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003809, dice: 0.029459, loss: 0.016634\n",
      "val: bce: 0.003064, dice: 0.027702, loss: 0.015383\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 15/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.004415, dice: 0.028803, loss: 0.016609\n",
      "val: bce: 0.003084, dice: 0.028535, loss: 0.015809\n",
      "0m 50s\n",
      "Epoch 16/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.005792, dice: 0.029193, loss: 0.017493\n",
      "val: bce: 0.003654, dice: 0.026453, loss: 0.015053\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 17/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003142, dice: 0.024023, loss: 0.013583\n",
      "val: bce: 0.003276, dice: 0.029774, loss: 0.016525\n",
      "0m 50s\n",
      "Epoch 18/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003350, dice: 0.022550, loss: 0.012950\n",
      "val: bce: 0.003053, dice: 0.022224, loss: 0.012638\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 19/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003137, dice: 0.021792, loss: 0.012465\n",
      "val: bce: 0.002581, dice: 0.020907, loss: 0.011744\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 20/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002789, dice: 0.020375, loss: 0.011582\n",
      "val: bce: 0.002735, dice: 0.021540, loss: 0.012138\n",
      "0m 50s\n",
      "Epoch 21/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002772, dice: 0.022897, loss: 0.012834\n",
      "val: bce: 0.002839, dice: 0.025318, loss: 0.014079\n",
      "0m 50s\n",
      "Epoch 22/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.006774, dice: 0.030107, loss: 0.018440\n",
      "val: bce: 0.012458, dice: 0.038054, loss: 0.025256\n",
      "0m 50s\n",
      "Epoch 23/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.005297, dice: 0.030096, loss: 0.017697\n",
      "val: bce: 0.003409, dice: 0.027578, loss: 0.015493\n",
      "0m 50s\n",
      "Epoch 24/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003192, dice: 0.026469, loss: 0.014831\n",
      "val: bce: 0.003121, dice: 0.026438, loss: 0.014780\n",
      "0m 50s\n",
      "Epoch 25/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003174, dice: 0.023550, loss: 0.013362\n",
      "val: bce: 0.002613, dice: 0.022625, loss: 0.012619\n",
      "0m 50s\n",
      "Epoch 26/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002651, dice: 0.021549, loss: 0.012100\n",
      "val: bce: 0.002263, dice: 0.021118, loss: 0.011691\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 27/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.003494, dice: 0.021877, loss: 0.012685\n",
      "val: bce: 0.006482, dice: 0.034024, loss: 0.020253\n",
      "0m 50s\n",
      "Epoch 28/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.002742, dice: 0.021010, loss: 0.011876\n",
      "val: bce: 0.002412, dice: 0.019662, loss: 0.011037\n",
      "saving best model\n",
      "0m 50s\n",
      "Epoch 29/59\n",
      "----------\n",
      "LR 1e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from unet import training_loop\n",
    "reload(training_loop)\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
    "\n",
    "model, loss_values = training_loop.train_model(model, optimizer_ft, exp_lr_scheduler, dataloaders, num_epochs=60)\n",
    "\n",
    "np.save('checkpoints/baseSegmentationModelMetrics.npz', loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustdg",
   "language": "python",
   "name": "robustdg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
